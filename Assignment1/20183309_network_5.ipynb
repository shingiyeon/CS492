{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_steps': None, '_task_id': 0, '_session_config': None, '_keep_checkpoint_every_n_hours': 10000, '_task_type': 'worker', '_service': None, '_num_ps_replicas': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x0000021C285778D0>, '_model_dir': './CNN_layer5', '_evaluation_master': '', '_log_step_count_steps': 100, '_save_checkpoints_secs': 600, '_keep_checkpoint_max': 5, '_master': '', '_global_id_in_cluster': 0, '_save_summary_steps': 100, '_num_worker_replicas': 1, '_train_distribute': None, '_tf_random_seed': None, '_is_chief': True}\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after 30 secs (eval_spec.throttle_secs) or training is finished.\n",
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "Tensor(\"ArgMax_1:0\", shape=(?,), dtype=int64)\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-06-07-18:22:34\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./CNN_layer5\\model.ckpt-10001\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Finished evaluation at 2018-06-07-18:22:34\n",
      "INFO:tensorflow:Saving dict for global step 10001: accuracy = 0.9025, global_step = 10001, loss = 0.40590546\n",
      "evaluation\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "Tensor(\"ArgMax_1:0\", shape=(?,), dtype=int64)\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-06-07-18:22:34\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./CNN_layer5\\model.ckpt-10001\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-06-07-18:22:35\n",
      "INFO:tensorflow:Saving dict for global step 10001: accuracy = 0.9025, global_step = 10001, loss = 0.40590546\n",
      "{'global_step': 10001, 'loss': 0.40590546, 'accuracy': 0.9025}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./CNN_layer5\\model.ckpt-10001\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "batch_size = 100\n",
    "\n",
    "def make_onehot_vector(labels): \n",
    "    length = len(labels)\n",
    "    a = np.zeros((length, 10))\n",
    "    \n",
    "    for i in range(length):\n",
    "        a[i][labels[i]] = 1.0\n",
    "        \n",
    "    return a\n",
    "\n",
    "def dense_batch_relu(x, phase, unit, scope, dropout_rate=0.30):\n",
    "    with tf.variable_scope(scope):\n",
    "        reg = tf.contrib.layers.l2_regularizer(scale=0.005)\n",
    "        l1 = tf.layers.dense(x, unit, activation=None, kernel_regularizer=reg)\n",
    "        l2 = tf.contrib.layers.batch_norm(l1, center=True, scale=True)\n",
    "        l3 = tf.layers.dropout(l2, dropout_rate, training=phase)\n",
    "        \n",
    "        return tf.nn.relu(l3, 'relu')\n",
    "\n",
    "def cnn(input_layer, filters, kernel_size, pool_size, strides, phase, dropout_rate=0.2):\n",
    "    conv1 = tf.layers.conv2d(\n",
    "        inputs=input_layer,\n",
    "        filters=filters,\n",
    "        kernel_size=kernel_size,\n",
    "        padding=\"same\",\n",
    "        activation=tf.nn.relu)\n",
    "    pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=pool_size, strides=strides)\n",
    "    dropout_layer = tf.layers.dropout(pool1, dropout_rate, training=phase)\n",
    "    return dropout_layer\n",
    "    \n",
    "def augmentation(images, conversion=False, rotater=True):\n",
    "    transforms_list = []\n",
    "    c = tf.constant(28.0, dtype=tf.float32)\n",
    "    original = tf.constant([1,0,0,0,1,0,0,0], dtype=tf.float32)\n",
    "    if rotater == True:\n",
    "        angles = tf.random_normal([batch_size], -math.pi, math.pi) \n",
    "        transforms_list.append( tf.contrib.image.angles_to_projective_transforms(angles, c, c))\n",
    "    if conversion==True:\n",
    "        binomial_prob = tf.less(tf.random_uniform([batch_size], -1.0, 1.0), 0.0) \n",
    "        flip_transform = tf.convert_to_tensor( [1, 0, 0, 0, -1, c, 0, 0], dtype=tf.float32) \n",
    "        transforms_list.append( tf.where(binomial_prob, tf.tile(tf.expand_dims(flip_transform, 0), [batch_size, 1]), \n",
    "                     tf.tile(tf.expand_dims(original, 0), [batch_size, 1]))) \n",
    "    images = tf.contrib.image.transform(images, tf.contrib.image.compose_transforms(*transforms_list), interpolation='NEAREST')\n",
    "    return images\n",
    "    \n",
    "\n",
    "def custom_model_fn(features, labels, mode):\n",
    "    \"\"\"Model function for PA1\"\"\"\n",
    "    with tf.device('/cpu:0'):\n",
    "    # Input Layer\n",
    "        input_layer = tf.reshape(features['x'], [-1, 28, 28, 1])\n",
    "        check_train = (mode == tf.estimator.ModeKeys.TRAIN)\n",
    "    #     float(i)\n",
    "        if check_train == True:\n",
    "            augmented_data = list()\n",
    "            augmented_data.append(augmentation(input_layer, conversion=True, rotater=False))\n",
    "            for i in range(1, 8):\n",
    "                augmented_data.append(augmentation(input_layer, conversion=True))\n",
    "            for i in range(1, 8):\n",
    "                augmented_data.append(augmentation(input_layer, conversion=False))            \n",
    "            for i in range(0, 15):\n",
    "                input_layer = tf.concat([input_layer, augmented_data[i]], 0)\n",
    "            labels = tf.concat([labels, labels], 0)\n",
    "            labels = tf.concat([labels, labels], 0)\n",
    "            labels = tf.concat([labels, labels], 0)\n",
    "            labels = tf.concat([labels, labels], 0)\n",
    "\n",
    "        input_layer = tf.reshape(input_layer, [-1, 28, 28, 1])\n",
    "\n",
    "    '''Hidden Layer'''\n",
    "    with tf.device('/gpu:0'):\n",
    "        L1 = cnn(input_layer, 32, [5,5], [2,2], 2, phase=check_train)\n",
    "        L2 = cnn(L1, 64, [5,5], [2,2], 2, phase=check_train)\n",
    "        L3 = cnn(L2, 128, [5,5], [2,2], 2, phase=check_train)\n",
    "        L3_flat = tf.reshape(L3, [-1, 128*3*3])\n",
    "        L4 = dense_batch_relu(L3_flat, check_train, 1024, 'L2')\n",
    "        logits = tf.layers.dense(inputs=L4, units=10, activation=None)\n",
    "\n",
    "        predictions = {\n",
    "          \"classes\": tf.argmax(input=logits, axis=1),\n",
    "          \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n",
    "        }\n",
    "\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=labels)) + tf.losses.get_regularization_loss()\n",
    "\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        optimizer = tf.train.AdamOptimizer(0.0005) # Refer to tf.train\n",
    "        train_op = optimizer.minimize(loss=loss, global_step=tf.train.get_global_step())\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
    "\n",
    "    Y = tf.argmax(labels, 1)\n",
    "    print(Y)\n",
    "    eval_metric_ops = {\"accuracy\": tf.metrics.accuracy(labels=Y, predictions=predictions[\"classes\"])}\n",
    "    return tf.estimator.EstimatorSpec(mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Write your dataset path\n",
    "    dataset_train = np.load('./train.npy')\n",
    "    dataset_eval =  np.load('./valid.npy')\n",
    "    test_data =  np.load('./test.npy')\n",
    "\n",
    "    train_data = dataset_train[:,:784]\n",
    "    train_labels = dataset_train[:,784].astype(np.int32)\n",
    "    \n",
    "\n",
    "    train_labels_onehot = make_onehot_vector(train_labels)\n",
    "    \n",
    "    eval_data = dataset_eval[:,:784]\n",
    "    eval_labels = dataset_eval[:,784].astype(np.int32)\n",
    "    eval_labels_onehot = make_onehot_vector(eval_labels)\n",
    "    \n",
    "#     config = tf.ConfigProto()\n",
    "#     config.gpu_options.allow_growth = True\n",
    "    \n",
    "    # Save model and checkpoint\n",
    "    classifier = tf.estimator.Estimator(model_fn=custom_model_fn, model_dir=\"./CNN_layer5\")\n",
    "\n",
    "    # Set up logging for predictions\n",
    "    tensors_to_log = {\"probabilities\": \"softmax_tensor\"}\n",
    "    logging_hook = tf.train.LoggingTensorHook(tensors=tensors_to_log, every_n_iter=2000)\n",
    "\n",
    "    # Train the model. You can train your model with specific batch size and epoches\n",
    "    train_input = tf.estimator.inputs.numpy_input_fn(x={\"x\": train_data},\n",
    "        y=train_labels_onehot, batch_size=batch_size, num_epochs=5, shuffle=True)\n",
    "    train_spec = tf.estimator.TrainSpec(input_fn = train_input, max_steps=8001)\n",
    "\n",
    "    # Eval the model. You can evaluate your trained model with validation data\n",
    "    eval_input = tf.estimator.inputs.numpy_input_fn(x={\"x\": eval_data},\n",
    "        y=eval_labels_onehot, num_epochs=1, shuffle=False)\n",
    "    eval_spec = tf.estimator.EvalSpec(input_fn = eval_input, throttle_secs = 30)\n",
    "    \n",
    "    tf.estimator.train_and_evaluate(classifier, train_spec, eval_spec)\n",
    "    print(\"evaluation\")\n",
    "    eval_results = classifier.evaluate(input_fn=eval_input)\n",
    "    print(eval_results)\n",
    "\n",
    "    ## ----------- Do not modify!!! ------------ ##\n",
    "    # Predict the test dataset\n",
    "    pred_input = tf.estimator.inputs.numpy_input_fn(x={\"x\": test_data}, shuffle=False)\n",
    "    pred_results = classifier.predict(input_fn=pred_input)\n",
    "    pred_list = list(pred_results)\n",
    "    result = np.asarray([list(x.values())[1] for x in pred_list])\n",
    "    ## ----------------------------------------- ##\n",
    "\n",
    "    np.save('./20183309_network_5.npy', result)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
